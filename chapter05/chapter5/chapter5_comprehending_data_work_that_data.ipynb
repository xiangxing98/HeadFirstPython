{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5. Comprehending data: Work that data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Python Toolbox\n",
    "\n",
    "### Python Lingo\n",
    "- In-place sorting\n",
    "- copied sorting\n",
    "- method chaining\n",
    "- function chaining\n",
    "\n",
    "### More Python Lingo\n",
    "- list comprehension\n",
    "- a slice\n",
    "- a set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coach Kelly needs your elp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do This!  - Download the four data files from the support site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercises\n",
    "\n",
    "- read data from each file into its own list\n",
    "- display lists on screen\n",
    "\n",
    "> *try splitting data on the commas, and don't forget to strip unwanted whitespace*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2-34', '3:21', '2.34', '2.45', '3.01', '2:01', '2:01', '3:10', '2-22']\n",
      "['2.59', '2.11', '2:11', '2:23', '3-10', '2-23', '3:10', '3.21', '3-21']\n",
      "['2:22', '3.01', '3:01', '3.02', '3:02', '3.02', '3:22', '2.49', '2:38']\n",
      "['2:58', '2.58', '2:39', '2-25', '2-55', '2:54', '2.18', '2:55', '2:55']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "try:\n",
    "    with open('./hfpy_ch5_data/james.txt') as james_file:\n",
    "        james_data = james_file.readline()\n",
    "         \n",
    "    james = james_data.strip().split(',')\n",
    "    \n",
    "    with open('./hfpy_ch5_data/julie.txt') as julie_file:\n",
    "        julie_data = julie_file.readline()\n",
    "    \n",
    "    julie = julie_data.strip().split(',')\n",
    "    \n",
    "    with open('./hfpy_ch5_data/mikey.txt') as mikey_file:\n",
    "        mikey_data = mikey_file.readline()\n",
    "    \n",
    "    mikey = mikey_data.strip().split(',')\n",
    "    \n",
    "    with open('./hfpy_ch5_data/sarah.txt') as sarah_file:\n",
    "        sarah_data = sarah_file.readline()\n",
    "    sarah = sarah_data.strip().split(',')\n",
    "    \n",
    "    \n",
    "        \n",
    "except IOError as err:\n",
    "    print(\"IOError: \" + str(err))\n",
    "    \n",
    "except pickle.PickleError as perr:\n",
    "    print(\"Pickling error: \" + str(perr))\n",
    "\n",
    "    \n",
    "print(james)\n",
    "print(julie)\n",
    "print(mikey)\n",
    "print(sarah)\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**An idle sorting session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 3, 1, 2, 4, 5]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [6,3,1,2,4,5]\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 3, 1, 2, 4, 5]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [6,3,1,2,4,5]\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n",
      "[6, 3, 1, 2, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data2 = sorted(data)\n",
    "print(data2)\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sharpen Pencil - sort data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2-22', '2-34', '2.34', '2.45', '2:01', '2:01', '3.01', '3:10', '3:21']\n",
      "['2-23', '2.11', '2.59', '2:11', '2:23', '3-10', '3-21', '3.21', '3:10']\n",
      "['2.49', '2:22', '2:38', '3.01', '3.02', '3.02', '3:01', '3:02', '3:22']\n",
      "['2-25', '2-55', '2.18', '2.58', '2:39', '2:54', '2:55', '2:55', '2:58']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "try:\n",
    "    with open('./hfpy_ch5_data/james.txt') as james_file:\n",
    "        james_data = james_file.readline()\n",
    "         \n",
    "    james = james_data.strip().split(',')\n",
    "    \n",
    "    with open('./hfpy_ch5_data/julie.txt') as julie_file:\n",
    "        julie_data = julie_file.readline()\n",
    "    \n",
    "    julie = julie_data.strip().split(',')\n",
    "    \n",
    "    with open('./hfpy_ch5_data/mikey.txt') as mikey_file:\n",
    "        mikey_data = mikey_file.readline()\n",
    "    \n",
    "    mikey = mikey_data.strip().split(',')\n",
    "    \n",
    "    with open('./hfpy_ch5_data/sarah.txt') as sarah_file:\n",
    "        sarah_data = sarah_file.readline()\n",
    "    sarah = sarah_data.strip().split(',')\n",
    "    \n",
    "    \n",
    "        \n",
    "except IOError as err:\n",
    "    print(\"IOError: \" + str(err))\n",
    "    \n",
    "except pickle.PickleError as perr:\n",
    "    print(\"Pickling error: \" + str(perr))\n",
    "\n",
    "\n",
    "print(sorted(james))\n",
    "print(sorted(julie))\n",
    "print(sorted(mikey))\n",
    "print(sorted(sarah))\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Chaining Test Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sanitize(time_string):    \n",
    "    if '-' in time_string:\n",
    "        splitter = '-'\n",
    "    elif ':' in time_string:\n",
    "        splitter = ':'\n",
    "    else:\n",
    "        return time_string\n",
    "    \n",
    "    (mins, secs) = time_string.split(splitter)\n",
    "    \n",
    "    return (mins + '.' + secs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.01', '2.01', '2.22', '2.34', '2.34', '2.45', '3.01', '3.10', '3.21']\n",
      "['2.11', '2.11', '2.23', '2.23', '2.59', '3.10', '3.10', '3.21', '3.21']\n",
      "['2.22', '2.38', '2.49', '3.01', '3.01', '3.02', '3.02', '3.02', '3.22']\n",
      "['2.18', '2.25', '2.39', '2.54', '2.55', '2.55', '2.55', '2.58', '2.58']\n"
     ]
    }
   ],
   "source": [
    "james_s = []\n",
    "for time in james:\n",
    "    james_s.append(sanitize(time))\n",
    "    \n",
    "julie_s = []\n",
    "for time in julie:\n",
    "    julie_s.append(sanitize(time))\n",
    "    \n",
    "mikey_s = []\n",
    "for time in mikey:\n",
    "    mikey_s.append(sanitize(time))\n",
    "\n",
    "sarah_s = []\n",
    "for time in sarah:\n",
    "    sarah_s.append(sanitize(time))\n",
    "\n",
    "\n",
    "print(sorted(james_s))\n",
    "print(sorted(julie_s))\n",
    "print(sorted(mikey_s))\n",
    "print(sorted(sarah_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehending Lists\n",
    "> 4 things need to happen to transform a list into another\n",
    "1. create new list to hold data\n",
    "2. iterate each data item in original list\n",
    "3. on each iteration perform transformantion\n",
    "4. append the transformed data to new list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_mikey = []            # 1. create\n",
    "for each_t in mikey:        # 2. iterate\n",
    "    clean_mikey.append(sanitize(each_t))  # 3. & 4. transform & append\n",
    "\n",
    "## vs comprehending lists\n",
    "\n",
    "clean_mikey = [sanitize(each_t) for each_t in mikey]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List Comprehension Version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.01', '2.01', '2.22', '2.34', '2.34', '2.45', '3.01', '3.10', '3.21']\n",
      "['2.11', '2.11', '2.23', '2.23', '2.59', '3.10', '3.10', '3.21', '3.21']\n",
      "['2.22', '2.38', '2.49', '3.01', '3.01', '3.02', '3.02', '3.02', '3.22']\n",
      "['2.18', '2.25', '2.39', '2.54', '2.55', '2.55', '2.55', '2.58', '2.58']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "james_s = [sanitize(time) for time in james]\n",
    "julie_s = [sanitize(time) for time in julie]\n",
    "mikey_s = [sanitize(time) for time in mikey]\n",
    "sarah_s = [sanitize(time) for time in sarah]\n",
    "\n",
    "print(sorted(james_s))\n",
    "print(sorted(julie_s))\n",
    "print(sorted(mikey_s))\n",
    "print(sorted(sarah_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List comprehension examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60, 120, 180]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mins = [1,2,3]\n",
    "secs = [m * 60 for m in mins]\n",
    "secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.281, 32.81, 9.843]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meters = [1, 10, 3]\n",
    "feet = [m * 3.281 for m in meters]\n",
    "feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', \"DON'T\", 'LIKE', 'SPAM']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower = [\"I\", \"don't\", \"like\", \"spam\"]\n",
    "upper = [s.upper() for s in lower]\n",
    "upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.22', '2.22', '2.22']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty = ['2-22', '2:22', '2.22']\n",
    "clean = [sanitize(t) for t in dirty]\n",
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.22, 2.22, 2.22]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = [float(s) for s in clean]\n",
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.22, 3.33, 4.44]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = [float(sanitize(t)) for t in ['2-22', '3:33', '4.44']]\n",
    "clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write 4 list comprehensions to process lists of timing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.11', '2.11', '2.23', '2.23', '2.59', '3.10', '3.10', '3.21', '3.21']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "james_s = sorted([sanitize(time) for time in james])\n",
    "\n",
    "julie_s = sorted([sanitize(time) for time in julie])\n",
    "mikey_s = sorted([sanitize(time) for time in mikey])\n",
    "sarah_s = sorted([sanitize(time) for time in sarah])\n",
    "\n",
    "\n",
    "julie_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Drive List Comprehension - whith Coach Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.01', '2.01', '2.22', '2.34', '2.34', '2.45', '3.01', '3.10', '3.21']\n",
      "['2.11', '2.11', '2.23', '2.23', '2.59', '3.10', '3.10', '3.21', '3.21']\n",
      "['2.22', '2.38', '2.49', '3.01', '3.01', '3.02', '3.02', '3.02', '3.22']\n",
      "['2.18', '2.25', '2.39', '2.54', '2.55', '2.55', '2.55', '2.58', '2.58']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "try:\n",
    "    with open('./hfpy_ch5_data/james.txt') as james_file:\n",
    "        james_data = james_file.readline()\n",
    "         \n",
    "    james = james_data.strip().split(',')\n",
    "    \n",
    "    with open('./hfpy_ch5_data/julie.txt') as julie_file:\n",
    "        julie_data = julie_file.readline()\n",
    "    \n",
    "    julie = julie_data.strip().split(',')\n",
    "    \n",
    "    with open('./hfpy_ch5_data/mikey.txt') as mikey_file:\n",
    "        mikey_data = mikey_file.readline()\n",
    "    \n",
    "    mikey = mikey_data.strip().split(',')\n",
    "    \n",
    "    with open('./hfpy_ch5_data/sarah.txt') as sarah_file:\n",
    "        sarah_data = sarah_file.readline()\n",
    "    sarah = sarah_data.strip().split(',')\n",
    "    \n",
    "    \n",
    "        \n",
    "except IOError as err:\n",
    "    print(\"IOError: \" + str(err))\n",
    "    \n",
    "except pickle.PickleError as perr:\n",
    "    print(\"Pickling error: \" + str(perr))\n",
    "\n",
    "\n",
    "print(sorted([sanitize(t) for t in james]))\n",
    "print(sorted([sanitize(t) for t in julie]))\n",
    "print(sorted([sanitize(t) for t in mikey]))\n",
    "print(sorted([sanitize(t) for t in sarah]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "james[0], james[1], james[2], or james[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate to remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.01\n",
      "2.22\n",
      "2.34\n"
     ]
    }
   ],
   "source": [
    "james = sorted([sanitize(t) for t in james])\n",
    "\n",
    "unique_james = []\n",
    "for each_t in james:\n",
    "    if not each_t in unique_james:\n",
    "        unique_james.append(each_t)\n",
    "\n",
    "a = 0\n",
    "while( a != 3):\n",
    "    print(unique_james[a])\n",
    "    a +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.01', '2.22', '2.34']\n"
     ]
    }
   ],
   "source": [
    "unique_james = []\n",
    "\n",
    "for each_t in james:\n",
    "    if each_t not in unique_james:\n",
    "        unique_james.append(each_t)\n",
    "\n",
    "print(unique_james[0:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.11', '2.23', '2.59']\n",
      "['2.22', '2.38', '2.49']\n",
      "['2.18', '2.25', '2.39']\n"
     ]
    }
   ],
   "source": [
    "julie = sorted([sanitize(t) for t in julie])\n",
    "mikey = sorted([sanitize(t) for t in mikey])\n",
    "sarah = sorted([sanitize(t) for t in sarah])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "unique_julie = []\n",
    "\n",
    "for each_t in julie:\n",
    "    if each_t not in unique_julie:\n",
    "        unique_julie.append(each_t)\n",
    "\n",
    "print(unique_julie[0:3])\n",
    "\n",
    "unique_mikey = []\n",
    "for each_t in mikey:\n",
    "    if each_t not in unique_mikey:\n",
    "        unique_mikey.append(each_t)\n",
    "\n",
    "print(unique_mikey[0:3])\n",
    "\n",
    "unique_sarah = []\n",
    "for each_t in sarah:\n",
    "    if each_t not in unique_sarah:\n",
    "        unique_sarah.append(each_t)\n",
    "\n",
    "print(unique_sarah[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Duplicates With Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8, 10.6, 11, 'two', 7}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = set()\n",
    "\n",
    "distances = {10.6, 11, 8, 10.6, \"two\", 7}\n",
    "\n",
    "distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.01', '2.01', '2.22', '2.34', '2.34', '2.45', '3.01', '3.10', '3.21']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = set(james)\n",
    "james"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.01', '2.22', '2.34']\n",
      "['2.11', '2.23', '2.59']\n",
      "['2.22', '2.38', '2.49']\n",
      "['2.18', '2.25', '2.39']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "try:\n",
    "    with open('./hfpy_ch5_data/james.txt') as james_file:\n",
    "        james_data = james_file.readline()\n",
    "         \n",
    "    james = james_data.strip().split(',')\n",
    "    \n",
    "    with open('./hfpy_ch5_data/julie.txt') as julie_file:\n",
    "        julie_data = julie_file.readline()\n",
    "    \n",
    "    julie = julie_data.strip().split(',')\n",
    "    \n",
    "    with open('./hfpy_ch5_data/mikey.txt') as mikey_file:\n",
    "        mikey_data = mikey_file.readline()\n",
    "    \n",
    "    mikey = mikey_data.strip().split(',')\n",
    "    \n",
    "    with open('./hfpy_ch5_data/sarah.txt') as sarah_file:\n",
    "        sarah_data = sarah_file.readline()\n",
    "    sarah = sarah_data.strip().split(',')\n",
    "    \n",
    "    \n",
    "        \n",
    "except IOError as err:\n",
    "    print(\"IOError: \" + str(err))\n",
    "    \n",
    "except pickle.PickleError as perr:\n",
    "    print(\"Pickling error: \" + str(perr))\n",
    "\n",
    "\n",
    "james = sorted(set([sanitize(t) for t in james])) [0:3]\n",
    "julie = sorted(set([sanitize(t) for t in julie])) [0:3]\n",
    "mikey = sorted(set([sanitize(t) for t in mikey])) [0:3]\n",
    "sarah = sorted(set([sanitize(t) for t in sarah])) [0:3]\n",
    "\n",
    "print(james)\n",
    "print(julie)\n",
    "print(mikey)\n",
    "print(sarah)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.01', '2.22', '2.34']\n",
      "['2.11', '2.23', '2.59']\n",
      "['2.22', '2.38', '2.49']\n",
      "['2.18', '2.25', '2.39']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "def sanitize(time_string): \n",
    "    \"\"\"makes the list data uniform\"\"\"\n",
    "    if '-' in time_string:\n",
    "        splitter = '-'\n",
    "    elif ':' in time_string:\n",
    "        splitter = ':'\n",
    "    else:\n",
    "        return time_string\n",
    "    \n",
    "    (mins, secs) = time_string.split(splitter)\n",
    "    \n",
    "    return (mins + '.' + secs)\n",
    "\n",
    "def fileReader(string):\n",
    "    try:\n",
    "        with open(string) as some_file:\n",
    "            file_data = some_file.readline()\n",
    "        \n",
    "        file = file_data.strip().split(',')\n",
    "        \n",
    "        return file\n",
    "    \n",
    "    except IOError as err:\n",
    "        print(\"IOError: \" + str(err))\n",
    "    \n",
    "    except pickle.PickleError as perr:\n",
    "        print(\"Pickling error: \" + str(perr))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    james = './hfpy_ch5_data/james.txt'\n",
    "    julie = './hfpy_ch5_data/julie.txt'\n",
    "    mikey = './hfpy_ch5_data/mikey.txt'\n",
    "    sarah = './hfpy_ch5_data/sarah.txt'\n",
    "    \n",
    "    james = fileReader(james)\n",
    "    julie = fileReader(julie)\n",
    "    mikey = fileReader(mikey)\n",
    "    sarah = fileReader(sarah)\n",
    "    \n",
    "    \n",
    "james = sorted(set([sanitize(t) for t in james])) [0:3]\n",
    "julie = sorted(set([sanitize(t) for t in julie])) [0:3]\n",
    "mikey = sorted(set([sanitize(t) for t in mikey])) [0:3]\n",
    "sarah = sorted(set([sanitize(t) for t in sarah])) [0:3]\n",
    "\n",
    "print(james)\n",
    "print(julie)\n",
    "print(mikey)\n",
    "print(sarah)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
